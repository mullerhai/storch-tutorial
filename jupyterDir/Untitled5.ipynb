{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de038d2a-aa70-4d6a-840d-066a627c0757",
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    " * Copyright 2022 storch.dev\n",
    " *\n",
    " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    " * you may not use this file except in compliance with the License.\n",
    " * You may obtain a copy of the License at\n",
    " *\n",
    " *     http://www.apache.org/licenses/LICENSE-2.0\n",
    " *\n",
    " * Unless required by applicable law or agreed to in writing, software\n",
    " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    " * See the License for the specific language governing permissions and\n",
    " * limitations under the License.\n",
    " */\n",
    "\n",
    "//> using scala \"3.3\"\n",
    "//> using repository \"sonatype:snapshots\"\n",
    "//> using repository \"sonatype-s01:snapshots\"\n",
    "//> using lib \"dev.storch::vision:0.0-2fff591-SNAPSHOT\"\n",
    "// replace with pytorch-platform-gpu if you have a CUDA capable GPU\n",
    "//> using lib \"org.bytedeco:pytorch-platform:2.1.2-1.5.10\"\n",
    "// enable for CUDA support\n",
    "////> using lib \"org.bytedeco:cuda-platform-redist:12.3-8.9-1.5.10\"\n",
    "// enable for native Apple Silicon support\n",
    "// will not be needed with newer versions of pytorch-platform\n",
    "////> using lib \"org.bytedeco:pytorch:2.1.2-1.5.10,classifier=macosx-arm64\"\n",
    "\n",
    "import org.bytedeco.javacpp.{FloatPointer, PointerScope}\n",
    "import org.bytedeco.pytorch.{Example, InputArchive, OutputArchive, TensorExampleVectorIterator}\n",
    "import torch.Device.{CPU, CUDA}\n",
    "import torch.data.dataset.ChunkSharedBatchDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.modules.HasParams\n",
    "import torch.optim.Adam\n",
    "import torch.*\n",
    "import torchvision.datasets.FashionMNIST\n",
    "//import torchvision.datasets.FashionMNIST\n",
    "import torch.tqdm.Tqdm.tqdm\n",
    "\n",
    "import java.nio.file.Paths\n",
    "//import scala.runtime.stdLibPatches.Predef.nn\n",
    "import torch.internal.NativeConverters.{fromNative, toNative}\n",
    "\n",
    "import scala.util.{Random, Using}\n",
    "\n",
    "//// Define the model architecture\n",
    "class LstmNet[D <: BFloat16 | Float32 : Default](\n",
    "                                                  inputSize: Int = 28,\n",
    "                                                  hiddenSize: Int = 128,\n",
    "                                                  numLayers: Int = 2,\n",
    "                                                  numClasses: Int = 10\n",
    "                                                ) extends HasParams[D] {\n",
    "\n",
    "  val lstm = register(nn.LSTM(inputSize, hiddenSize, numLayers, batch_first = true))\n",
    "  val fc = register(nn.Linear(hiddenSize, numClasses))\n",
    "\n",
    "  def apply(i: Tensor[D]): Tensor[D] =\n",
    "    val arr = Seq(numLayers, i.size.head, hiddenSize.toInt)\n",
    "    val h0 = torch.zeros(size = arr, dtype = i.dtype)\n",
    "    val c0 = torch.zeros(size = arr, dtype = i.dtype)\n",
    "    val outTuple3 = lstm(i, Some(h0), Some(c0))\n",
    "    var out: Tensor[D] = outTuple3._1\n",
    "    out = out.index(torch.indexing.::, -1, ::)\n",
    "    F.logSoftmax(fc(out), dim = 1)\n",
    "\n",
    "}\n",
    "\n",
    "class RnnNet[D <: BFloat16 | Float32 : Default](\n",
    "                                                 inputSize: Int = 28,\n",
    "                                                 hiddenSize: Int = 128,\n",
    "                                                 numLayers: Int = 2,\n",
    "                                                 numClasses: Int = 10\n",
    "                                               ) extends HasParams[D] {\n",
    "\n",
    "  val rnn = register(nn.RNN(inputSize, hiddenSize, numLayers, batch_first = true))\n",
    "  val fc = register(nn.Linear(hiddenSize, numClasses))\n",
    "\n",
    "  def apply(i: Tensor[D]): Tensor[D] =\n",
    "    val arr = Seq(numLayers, i.size.head, hiddenSize.toInt)\n",
    "    val h0 = torch.zeros(size = arr, dtype = i.dtype)\n",
    "    val c0 = torch.zeros(size = arr, dtype = i.dtype)\n",
    "    val outTuple2 = rnn(i, Some(h0))\n",
    "    var out: Tensor[D] = outTuple2._1\n",
    "    out = out.index(torch.indexing.::, -1, ::)\n",
    "    F.logSoftmax(fc(out), dim = 1)\n",
    "\n",
    "}\n",
    "\n",
    "class GruNet[D <: BFloat16 | Float32 : Default](\n",
    "                                                 inputSize: Int = 28,\n",
    "                                                 hiddenSize: Int = 128,\n",
    "                                                 numLayers: Int = 2,\n",
    "                                                 numClasses: Int = 10\n",
    "                                               ) extends HasParams[D] {\n",
    "\n",
    "  val gru = register(nn.GRU(inputSize, hiddenSize, numLayers, batch_first = true))\n",
    "  val fc = register(nn.Linear(hiddenSize, numClasses))\n",
    "\n",
    "  def apply(i: Tensor[D]): Tensor[D] =\n",
    "    val arr = Seq(numLayers, i.size.head, hiddenSize.toInt)\n",
    "    val h0 = torch.zeros(size = arr, dtype = i.dtype)\n",
    "    val c0 = torch.zeros(size = arr, dtype = i.dtype)\n",
    "    val outTuple2 = gru(i, Some(h0))\n",
    "    var out: Tensor[D] = outTuple2._1\n",
    "    out = out.index(torch.indexing.::, -1, ::)\n",
    "    F.logSoftmax(fc(out), dim = 1)\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "/** Shows how to train a simple LstmNet on the MNIST dataset */\n",
    "object LstmNetApp extends App {\n",
    "  val device = if torch.cuda.isAvailable then CUDA else CPU\n",
    "  println(s\"Using device: $device\")\n",
    "//  val model  = GruNet().to(device)\n",
    "  //  val model = LstmNet().to(device)\n",
    "//  val model = RnnNet().to(device)\n",
    "  val modelPahth =\"D:\\\\data\\\\git\\\\storch-tutorial\\\\lstm-net.pt\"\n",
    "  val model = LstmNet().to(device)\n",
    "//  val input = new InputArchive()\n",
    "//  val mo = input.load_from(modelPahth)\n",
    "//  var modelz = new org.bytedeco.pytorch.Module()\n",
    "//  val model = modelz.load(input) //.asInstanceOf[LstmNet[Float32]]\n",
    "  //  val model  = TransformerClassifier(embedding_dim = 128 , num_heads= 6, num_layers=6, hidden_dim = 30, num_classes=10, dropout_rate=0.1).to(device)\n",
    "  // prepare data FashionMNIST\n",
    "  //  val dataPath = Paths.get(\"data/mnist\")\n",
    "  //  val mnistTrain = MNIST(dataPath, train = true, download = true)\n",
    "  //  val mnistEval = MNIST(dataPath, train = false)\n",
    "  // \"D:\\\\code\\\\data\\\\FashionMNIST\"\n",
    "  //  val dataPath = Paths.get(\"data/FashionMNIST\")\n",
    "  val dataPath = Paths.get(\"D:\\\\data\\\\FashionMNIST\")\n",
    "  val mnistTrain = FashionMNIST(dataPath, train = true, download = true)\n",
    "  val mnistEval = FashionMNIST(dataPath, train = false)\n",
    "  println(s\"model ${model.modules.toSeq.mkString(\" \\n\")}\")\n",
    "  println(s\"model ${model.summarize}\")\n",
    "  val lossFn = torch.nn.loss.CrossEntropyLoss()\n",
    "  // enable AMSGrad to avoid convergence issues\n",
    "  val optimizer = Adam(model.parameters, lr = 1e-3, amsgrad = true)\n",
    "  val optimizerCopy = Adam(model.parameters, lr = 1e-3, amsgrad = true)\n",
    "  val evalFeatures = mnistEval.features.to(device)\n",
    "  val evalTargets = mnistEval.targets.to(device)\n",
    "  val r = Random(seed = 0)\n",
    "  val exampleSeq = mnistTrain.map(x => new Example(x._1.native, x._2.native))\n",
    "\n",
    "  import org.bytedeco.pytorch.{ChunkDatasetOptions, Example, ExampleIterator, ExampleStack, ExampleVector, RandomSampler}\n",
    "  import torch.data.DataLoaderOptions\n",
    "  import torch.data.dataloader.*\n",
    "  import torch.data.datareader.ChunkDataReader\n",
    "  import torch.data.dataset.*\n",
    "  //  val ex1 = new Example(mnistTrain.features.native ,mnistTrain.targets.native)\n",
    "  val exampleVector = new ExampleVector(exampleSeq *)\n",
    "  //  val exampleTensorSeq = mnistTrain.map(x => new TensorExample(x._1.native))\n",
    "  //  val tensorExampleVector = new TensorExampleVector(exampleTensorSeq*)\n",
    "  //  val reader = new ChunkTensorDataReader()// new TensorExampleVectorReader()\n",
    "  //  reader(tensorExampleVector)\n",
    "  val reader = new ChunkDataReader()\n",
    "  //\n",
    "  //  val ds = new JavaDataset() {\n",
    "  //     val exampleVector = new ExampleVector(exampleSeq.toArray:_*)\n",
    "  //    override def get(index: Long): Example = exampleVector.get(index)\n",
    "  //\n",
    "  //    override def size = new SizeTOptional(exampleVector.size)\n",
    "  //\n",
    "  //  }\n",
    "  //  val ds = new JD(reader)//.map(new ExampleStack())\n",
    "  //val ds = new JSD() {\n",
    "  //  val exampleVector = reader.exampleVec\n",
    "  //\n",
    "  //  override def get_batch(size: Long): ExampleVector = exampleVector\n",
    "  //\n",
    "  //  override def size = new SizeTOptional(exampleVector.size)\n",
    "  //}\n",
    "  //val ds = new TD() {\n",
    "  //  val tex = reader.tensorExampleVec //new TensorExampleVector(new TensorExample(Tensor.create(10.0, 20.0, 50.0, 80.0, 100.0)), new TensorExample(Tensor.create(15.0, 30.0, 50.0, 80.0, 300.0)), new TensorExample(Tensor.create(20.0, 20.0, 50.0, 80.0, 100.0)), new TensorExample(Tensor.create(35.0, 30.0, 50.0, 80.0, 300.0)), new TensorExample(Tensor.create(40.0, 20.0, 50.0, 80.0, 100.0)), new TensorExample(Tensor.create(55.0, 30.0, 50.0, 80.0, 300.0)), new TensorExample(Tensor.create(60.0, 20.0, 50.0, 80.0, 100.0)), new TensorExample(Tensor.create(75.0, 30.0, 50.0, 80.0, 300.0)))\n",
    "  //\n",
    "  //  override def get(index: Long): TensorExample = {\n",
    "  //    tex.get(index)\n",
    "  //    //                    return super.get(index);\n",
    "  //  }\n",
    "  //\n",
    "  //  override def get_batch(indices: SizeTArrayRef): TensorExampleVector = tex //.get_batch(indices) // ds.get_batch(indices) // exampleVector\n",
    "  //\n",
    "  //  override def size = new SizeTOptional(tex.size)\n",
    "  //}\n",
    "  val batch_size = 32\n",
    "  val prefetch_count = 1\n",
    "  //  {\n",
    "  //    override def read_chunk(chunk_index: Long) = exampleVector //  new ExampleVector(new Example(Tensor.create(10.0, 20.0, 50.0, 80.0, 100.0), Tensor.create(200.0)), new Example(Tensor.create(15.0, 30.0, 50.0, 80.0, 300.0), Tensor.create(400.0)), new Example(Tensor.create(20.0, 20.0, 50.0, 80.0, 100.0), Tensor.create(500.0)), new Example(Tensor.create(35.0, 30.0, 50.0, 80.0, 300.0), Tensor.create(600.0)), new Example(Tensor.create(40.0, 20.0, 50.0, 80.0, 100.0), Tensor.create(700.0)), new Example(Tensor.create(55.0, 30.0, 50.0, 80.0, 300.0), Tensor.create(800.0)), new Example(Tensor.create(60.0, 20.0, 50.0, 80.0, 100.0), Tensor.create(900.0)), new Example(Tensor.create(75.0, 30.0, 50.0, 80.0, 300.0), Tensor.create(300.0)))\n",
    "  //\n",
    "  //    override def chunk_count:Long = 1\n",
    "  //\n",
    "  //    override def reset(): Unit = {\n",
    "  //    }\n",
    "  //  }\n",
    "  reader(exampleVector)\n",
    "  //  val ds = new ChunkSharedBatchDataset(new ChunkDataset(reader, new RandomSampler(exampleSeq.size), new RandomSampler(exampleSeq.size), new ChunkDatasetOptions(prefetch_count, batch_size))).map(new ExampleStack)\n",
    "  //  val ds  = new ChunkSharedTensorBatchDataset(new ChunkTensorDataset(reader,new RS(exampleTensorSeq.size),new ChunkDatasetOptions(prefetch_count, batch_size))).map(new TensorExampleStack)\n",
    "  val ds = new ChunkSharedBatchDataset(\n",
    "    new ChunkDataset(\n",
    "      reader,\n",
    "      new RandomSampler(exampleSeq.size),\n",
    "      new RandomSampler(exampleSeq.size),\n",
    "      new ChunkDatasetOptions(prefetch_count, batch_size)\n",
    "    )\n",
    "  ).map(new ExampleStack)\n",
    "  //  val ds = new TensorDataset(reader)\n",
    "  //  val ds = new StreamDataset(reader)\n",
    "  val opts = new DataLoaderOptions(32)\n",
    "  //  opts.enforce_ordering.put(true)\n",
    "  //  opts.drop_last.put(false)\n",
    "  val data_loader = new ChunkRandomDataLoader(ds, opts)\n",
    "\n",
    "  def dataLoader: Iterator[(torch.Tensor[Float32], torch.Tensor[Int64])] =\n",
    "    r.shuffle(mnistTrain).grouped(8).map { batch =>\n",
    "      val (features, targets) = batch.unzip\n",
    "      (torch.stack(features).to(device), torch.stack(targets).to(device))\n",
    "    }\n",
    "  //  opts.workers.put(5)\n",
    "  opts.batch_size.put(32)\n",
    "\n",
    "  def exampleVectorToExample(exVec: ExampleVector): Example = {\n",
    "    val example = new Example(exVec.get(0).data(), exVec.get(0).target())\n",
    "    example\n",
    "  }\n",
    "  //  val data_loader = new ChunkRandomTensorDataLoader(ds, opts)\n",
    "  //  val data_loader = new JavaDistributedSequentialTensorDataLoader(ds, new DSS(ds.size.get), opts)\n",
    "  //  val data_loader = new JavaDistributedRandomTensorDataLoader(ds, new DRS(ds.size.get), opts)\n",
    "  //  val data_loader = new JavaSequentialTensorDataLoader(ds, new SS(ds.size.get), opts)\n",
    "  //  val data_loader = new JavaStreamDataLoader(ds, new STS(ds.size.get), opts)\n",
    "  //  val data_loader = new JavaStreamDataLoader(ds, new STS(ds.size.get), opts)\n",
    "  //  val data_loader = new JavaStreamDataLoader(ds, new StreamSampler(ds.size.get), opts)\n",
    "  //  val data_loader = new RandomDataLoader(ds, new RS(ds.size.get), opts)\n",
    "  //  val data_loader = new SequentialDataLoader(ds, new SS(ds.size.get), opts)\n",
    "  //  val data_loader = new DistributedSequentialDataLoader(ds, new DistributedSequentialSampler(ds.size.get), opts)\n",
    "  //  val data_loader = new DistributedRandomDataLoader(ds, new DistributedRandomSampler(ds.size.get), opts)\n",
    "  //  val data_loader = new JavaRandomDataLoader(ds, new RandomSampler(ds.size.get), opts)\n",
    "  println(s\"ds.size.get {ds.size.get} data_loader option ${data_loader.options.batch_size()}\")\n",
    "  for (epoch <- tqdm(List(1, 2, 3, 4, 5, 6,7,8,9,10,11,12), \"iterating\",color =None,sleepSpeed = Some(50),colorRandom = false)) {\n",
    "    //    var it: ExampleVectorIterator = data_loader.begin\n",
    "    //    var it :TensorExampleVectorIterator = data_loader.begin\n",
    "    //    var it :TensorExampleIterator = data_loader.begin\n",
    "    var it: ExampleIterator = data_loader.begin\n",
    "    var batchIndex = 0\n",
    "    println(\"coming in for loop\")\n",
    "    while (!it.equals(data_loader.end)) {\n",
    "      Using.resource(new PointerScope()) { p =>\n",
    "        val batch = it.access\n",
    "        optimizer.zeroGrad()\n",
    "        val trainDataTensor = fromNative(batch.data())\n",
    "        val prediction = model(fromNative(batch.data()).reshape(-1, 28, 28))\n",
    "        val loss = lossFn(prediction, fromNative(batch.target()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        it = it.increment\n",
    "        batchIndex += 1\n",
    "        if batchIndex % 200 == 0 then\n",
    "          // run evaluation\n",
    "          val predictions = model(evalFeatures.reshape(-1, 28, 28))\n",
    "          val evalLoss = lossFn(predictions, evalTargets)\n",
    "          val featuresData = new Array[Float](1000)\n",
    "          val fp4 = new FloatPointer(predictions.native.data_ptr_float())\n",
    "          fp4.get(featuresData)\n",
    "          println(s\"\\n ffff size ${featuresData.size} shape ${\n",
    "            evalFeatures.shape\n",
    "              .mkString(\", \")\n",
    "          }a data ${featuresData.mkString(\" \")}\")\n",
    "          println(s\"predictions : ${predictions} \\n\")\n",
    "          println(s\"loss grad_fn: ${evalLoss.grad_fn()}\")\n",
    "          val accuracy =\n",
    "            (predictions.argmax(dim = 1).eq(evalTargets).sum / mnistEval.length).item\n",
    "          println(\n",
    "            f\"Epoch: $epoch | Batch: $batchIndex%4d | Training loss: ${loss.item}%.4f | Eval loss: ${evalLoss.item}%.4f | Eval accuracy: $accuracy%.4f\"\n",
    "          )\n",
    "        //        it = it.increment\n",
    "\n",
    "      }\n",
    "    }\n",
    "    optimizerCopy.add_parameters(model.namedParameters()) //\n",
    "    println(s\"optimizerCopy ${optimizerCopy}\")\n",
    "    println(s\"optimizer ${optimizer}\")\n",
    "    println(s\"judge optimizer ${optimizer == optimizerCopy}\")\n",
    "    println(s\"model parameters dict ${model.namedParameters()}\")\n",
    "  }\n",
    "\n",
    "  val archive = new OutputArchive\n",
    "  model.save(archive)\n",
    "  archive.save_to(\"lstm-net.pkl\")\n",
    "  //  //a.index(indexArrayRefA).add_(torch.mul(x.index(indexArrayRefX), a_prev.index(indexArrayRefA_prev)))\n",
    "  class PositionalEncoding[D <: BFloat16 | Float32 : Default](d_model: Long, max_len: Long = 28 * 28)\n",
    "    extends HasParams[D] {\n",
    "\n",
    "    import torch.{---, Slice}\n",
    "\n",
    "    val arr = Seq(max_len, d_model)\n",
    "    println(s\"First row: ${tensor(0)}\")\n",
    "    // First row: tensor dtype=float32, shape=[4], device=CPU\n",
    "    // [1.0000, 1.0000, 1.0000, 1.0000]\n",
    "    println(s\"First column: ${tensor(Slice(), 0)}\")\n",
    "    // First column: tensor dtype=float32, shape=[4], device=CPU\n",
    "    // [1.0000, 1.0000, 1.0000, 1.0000]\n",
    "    println(s\"Last column: ${tensor(---, -1)}\")\n",
    "    val position = torch.arange(0, max_len, dtype = this.paramType).unsqueeze(1)\n",
    "    val div_term =\n",
    "      torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.Tensor(10000.0)) / d_model))\n",
    "    val sinPosition = torch.sin(position * div_term).to(dtype = this.paramType)\n",
    "    val cosPosition = torch.cos(position * div_term).to(dtype = this.paramType)\n",
    "    val indexSin = torch.Tensor(Seq(0L, 1L))\n",
    "    val indexCos = torch.Tensor(Seq(1L, 1L))\n",
    "    var tensor = torch.ones(Seq(4, 4))\n",
    "    var encoding = torch.zeros(size = arr.map(_.toInt), dtype = this.paramType)\n",
    "    encoding.index(::, 1.::(13)).add(sinPosition)\n",
    "    encoding.index(::, Seq[Long](2, 1, 13)).add(sinPosition)\n",
    "    encoding.index(::, 13).equal(sinPosition)\n",
    "    encoding.update(indices = Seq(2.::(21), 1.::(13)), values = sinPosition)\n",
    "    encoding.update(indices = Seq(---, 2.::(21), 1.::(13)), values = sinPosition)\n",
    "    encoding.update(indices = Seq(---, ::(21), 1.::(13)), values = sinPosition)\n",
    "    encoding.update(indices = Seq(---, 1.::, 1.::(13)), values = sinPosition)\n",
    "    encoding.update(indices = Seq(---, ::, 1.::(13)), values = sinPosition)\n",
    "    encoding = encoding.to(dtype = this.paramType)\n",
    "    encoding = torch.indexCopy(encoding, 0, indexSin, sinPosition)\n",
    "    encoding = torch.indexCopy(encoding, 0, indexCos, cosPosition)\n",
    "    encoding = encoding.unsqueeze(0)\n",
    "\n",
    "    // return x + self.encoding[: ,: x.size(1)].to(x.device)\n",
    "    def apply(x: torch.Tensor[D]): torch.Tensor[D] =\n",
    "      x.add(encoding).to(x.device)\n",
    "  }\n",
    "\n",
    "\n",
    "  //\n",
    "  //   run training\n",
    "  //  for (epoch <- 1 to 50) do\n",
    "  //    for (batch <- dataLoader.zipWithIndex) do\n",
    "  //      // make sure we deallocate intermediate tensors in time shape [32,1,28,28]\n",
    "  //      Using.resource(new PointerScope()) { p =>\n",
    "  //        val ((feature, target), batchIndex) = batch\n",
    "  //        optimizer.zeroGrad()\n",
    "  //        val prediction = model(feature.reshape(-1,28,28))\n",
    "  //        val loss = lossFn(prediction, target)\n",
    "  //        loss.backward()\n",
    "  //        optimizer.step()\n",
    "  //        if batchIndex % 200 == 0 then\n",
    "  //          // run evaluation\n",
    "  //          val predictions= model(evalFeatures.reshape(-1,28,28))\n",
    "  //          val evalLoss = lossFn(predictions, evalTargets)\n",
    "  //          val featuresData  = new Array[Float](1000)\n",
    "  //          val fp4 = new FloatPointer(predictions.native.data_ptr_float())\n",
    "  //          fp4.get(featuresData)\n",
    "  //          println(s\"\\n ffff size ${featuresData.size} shape ${evalFeatures.shape.mkString(\", \")}a data ${featuresData.mkString(\" \" )}\")\n",
    "  //          println(s\"predictions : ${predictions} \\n\")\n",
    "  //          val accuracy =\n",
    "  //            (predictions.argmax(dim = 1).eq(evalTargets).sum / mnistEval.length).item\n",
    "  //          println(\n",
    "  //            f\"Epoch: $epoch | Batch: $batchIndex%4d | Training loss: ${loss.item}%.4f | Eval loss: ${evalLoss.item}%.4f | Eval accuracy: $accuracy%.4f\"\n",
    "  //          )\n",
    "  //      }\n",
    "\n",
    "  //}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a829b074-d44e-4cd0-aece-3609345176f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(console)\n",
      "-- Error: <splitter>:1:28 ------------------------------------------------------\n",
      "1 |! jt -t monokai -f fira -fs 13 -nf ptsans -nfs 11 -N -kl -cursw 5 -cursc r -cellw 95% -T\n",
      "  |                            ^\n",
      "  |                       end of statement expected but integer literal found"
     ]
    }
   ],
   "source": [
    "! jt -t monokai -f fira -fs 13 -nf ptsans -nfs 11 -N -kl -cursw 5 -cursc r -cellw 95% -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851afe33-230f-4110-852f-aaf7bd68eb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
